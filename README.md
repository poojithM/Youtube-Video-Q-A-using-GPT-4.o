# YouTube Video Q&A Streamlit Application

## Overview
This Streamlit application enables users to extract and analyze transcripts from YouTube videos using AI models. It uses OpenAI's Whisper model for converting video audio into text, stores transcript embeddings in a Chroma vector database, and utilizes the GPT-4.0 model for generating responses to user queries based on the video content.

## Features
- **YouTube Audio Extraction**: Extract audio from YouTube videos and convert it into text using the OpenAI Whisper model.
- **Text Chunking**: Split the transcript into manageable chunks for better processing.
- **Text Embedding**: Embed text chunks into a vector space using OpenAI's embedding model, storing the results in a Chroma vector database.
- **Interactive Q&A**: Users can ask questions about the video content, and the system provides answers by retrieving relevant information from the embedded text.

## Requirements
- Python 3.8 or later
- Streamlit
- dotenv
- langchain
- Chroma vector database library

## Installation
Clone this repository and navigate to the project directory. Install the required Python packages using the following command:

```bash
pip install -r requirements.txt
```

## Usage
To run the application, execute the following command in your terminal:

```bash

streamlit run app.py
```
- Navigate to the web browser to view and interact with the application.

## Interacting with the Application
- Enter a YouTube Video Link: Input the URL of the YouTube video you want to analyze in the sidebar.
- Temperature and Max Tokens Settings: Adjust these parameters to fine-tune the AI's response generation based on the embedded text.
- Ask Questions: Enter your questions about the video content in the input field, and receive answers generated by the AI.

## How It Works
The application processes video links through the following steps:
- **Transcript Extraction**: Audio from the provided YouTube video link is extracted and converted into text using OpenAI's Whisper model.
- **Text Chunking and Embedding**: The transcript text is chunked and each chunk is embedded into a vector space for efficient retrieval.
- **Response Generation**: When a user submits a query, the system retrieves the most relevant text chunk and uses the GPT-4.0 model to generate a response.
